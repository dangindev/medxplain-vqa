import torch
import torch.nn.functional as F
import numpy as np
import cv2
import logging
from PIL import Image

logger = logging.getLogger(__name__)

class GradCAM:
    """
    Grad-CAM implementation for BLIP model
    Based on "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization"
    """
    
    def __init__(self, model, layer_name="vision_model.encoder.layers.11"):
        """
        Initialize Grad-CAM with a model and target layer
        
        Args:
            model: BLIP model (can be BLIP2VQA wrapper or underlying model)
            layer_name: Target layer for Grad-CAM (typically the last convolutional layer)
        """
        # Handle both BLIP2VQA wrapper and underlying model
        if hasattr(model, 'model'):
            # This is BLIP2VQA wrapper
            self.model = model.model
            self.processor = model.processor  # Get processor from wrapper
        else:
            # This is the underlying model
            self.model = model
            self.processor = getattr(model, 'processor', None)
        
        self.layer_name = layer_name
        self.device = next(self.model.parameters()).device
        
        # Đăng ký hooks
        self.gradients = None
        self.activations = None
        self.hooks_registered = False
        
        # Đăng ký hooks
        self._register_hooks()
        
        logger.info(f"Grad-CAM initialized with layer: {layer_name}")
    
    def _register_hooks(self):
        """Đăng ký hooks để lấy gradients và activations"""
        if self.hooks_registered:
            logger.info("Hooks already registered")
            return
        
        # Tìm layer mục tiêu
        target_layer = self._find_target_layer()
        if target_layer is None:
            logger.error(f"Layer {self.layer_name} not found in model")
            return
        
        # Đăng ký forward hook
        def forward_hook(module, input, output):
            self.activations = output
        
        # Đăng ký backward hook
        def backward_hook(module, grad_input, grad_output):
            self.gradients = grad_output[0]
        
        # Gắn hooks
        self.forward_handle = target_layer.register_forward_hook(forward_hook)
        self.backward_handle = target_layer.register_full_backward_hook(backward_hook)
        
        self.hooks_registered = True
        logger.info("Hooks registered successfully")
    
    def _find_target_layer(self):
        """Tìm layer mục tiêu trong mô hình"""
        # Parse layer name
        if "." not in self.layer_name:
            return getattr(self.model, self.layer_name, None)
        
        # Xử lý nested layers
        parts = self.layer_name.split(".")
        current = self.model
        
        for part in parts:
            if hasattr(current, part):
                current = getattr(current, part)
            else:
                logger.error(f"Cannot find {part} in {current}")
                return None
        
        return current
    
    def remove_hooks(self):
        """Gỡ bỏ hooks để tránh memory leak"""
        if self.hooks_registered:
            self.forward_handle.remove()
            self.backward_handle.remove()
            self.hooks_registered = False
            logger.info("Hooks removed")
    
    def _preprocess_image(self, image):
        """
        Tiền xử lý hình ảnh nếu cần
        
        Args:
            image: PIL Image hoặc tensor
            
        Returns:
            tensor: Tensor đã xử lý
        """
        if isinstance(image, Image.Image):
            # Nếu dùng processor của BLIP để xử lý, trả về ngay
            return None
        
        if isinstance(image, torch.Tensor):
            # Đã là tensor, đưa lên đúng device
            return image.to(self.device)
        
        # Nếu không phải cả PIL Image và torch.Tensor, báo lỗi
        logger.error(f"Unsupported image type: {type(image)}")
        return None
    
    def _generate_cam(self, width, height):
        """
        Tạo bản đồ Grad-CAM từ gradients và activations
        
        Args:
            width: Chiều rộng của hình ảnh gốc
            height: Chiều cao của hình ảnh gốc
            
        Returns:
            numpy.ndarray: Grad-CAM heatmap
        """
        # Đảm bảo có gradients và activations
        if self.gradients is None or self.activations is None:
            logger.error("Gradients or activations not available")
            return None
        
        # Tính trọng số
        weights = torch.mean(self.gradients, dim=(2, 3), keepdim=True)
        
        # Tạo class activation map
        cam = torch.sum(weights * self.activations, dim=1, keepdim=True)
        cam = F.relu(cam)  # Chỉ giữ lại giá trị dương
        
        # Normalize
        if torch.max(cam) > 0:
            cam = cam / torch.max(cam)
        
        # Chuyển về numpy
        cam = cam.squeeze().cpu().detach().numpy()
        
        # Resize về kích thước hình ảnh gốc
        cam = cv2.resize(cam, (width, height))
        
        # Normalize lại để hiển thị
        cam = (cam - np.min(cam)) / (np.max(cam) - np.min(cam) + 1e-8)
        
        return cam
    
    def __call__(self, image, question=None, inputs=None, original_size=None):
        """
        Tạo Grad-CAM heatmap cho hình ảnh và câu hỏi
        
        Args:
            image: PIL Image hoặc tensor
            question: Câu hỏi (optional, can be None for image-only analysis)
            inputs: Đầu vào đã xử lý (nếu có)
            original_size: Kích thước gốc của hình ảnh (width, height)
            
        Returns:
            numpy.ndarray: Grad-CAM heatmap
        """
        self.model.eval()
        
        # Xác định kích thước
        if original_size is None:
            if isinstance(image, Image.Image):
                original_size = image.size  # (width, height)
            elif isinstance(image, torch.Tensor) and image.dim() == 3:
                # Tensor shape: C x H x W
                original_size = (image.shape[2], image.shape[1])  # (width, height)
            elif isinstance(image, torch.Tensor) and image.dim() == 4:
                # Tensor shape: B x C x H x W
                original_size = (image.shape[3], image.shape[2])  # (width, height)
        
        if original_size is None:
            logger.error("Cannot determine image size")
            return None
        
        width, height = original_size
        
        # Reset gradients
        self.model.zero_grad()
        
        # Xử lý đầu vào nếu chưa có
        if inputs is None:
            # FIXED: Kiểm tra processor availability
            if self.processor is None:
                logger.error("No processor available for input processing")
                return None
            
            try:
                # Xử lý hình ảnh và câu hỏi bằng processor của BLIP
                if question:
                    inputs = self.processor(
                        images=image,
                        text=question,
                        return_tensors="pt"
                    ).to(self.device)
                else:
                    # Image-only processing
                    inputs = self.processor(
                        images=image,
                        return_tensors="pt"
                    ).to(self.device)
            except Exception as e:
                logger.error(f"Error processing inputs: {e}")
                return None
        
        # Forward pass
        try:
            with torch.set_grad_enabled(True):
                # FIXED: Handle different model types and input formats
                if hasattr(inputs, 'pixel_values'):
                    # Standard BLIP inputs
                    if hasattr(inputs, 'input_ids') and inputs.input_ids is not None:
                        outputs = self.model(
                            input_ids=inputs.input_ids,
                            attention_mask=getattr(inputs, 'attention_mask', None),
                            pixel_values=inputs.pixel_values,
                            return_dict=True
                        )
                    else:
                        # Image-only inputs
                        outputs = self.model(
                            pixel_values=inputs.pixel_values,
                            return_dict=True
                        )
                else:
                    logger.error("Invalid input format for Grad-CAM")
                    return None
                
                # Tính target score - FIXED: More robust score calculation
                target_score = self._calculate_target_score(outputs)
                
                if target_score is None:
                    logger.error("Could not calculate target score")
                    return None
                
                # Backward pass
                target_score.backward()
                
        except Exception as e:
            logger.error(f"Error during forward/backward pass: {e}")
            return None
        
        # Tạo Grad-CAM
        grad_cam = self._generate_cam(width, height)
        
        # Reset gradients và activations
        self.gradients = None
        self.activations = None
        
        return grad_cam
    
    def _calculate_target_score(self, outputs):
        """
        FIXED: Calculate target score from model outputs
        
        Args:
            outputs: Model outputs
            
        Returns:
            torch.Tensor: Target score for backpropagation
        """
        try:
            # Try different output formats
            if hasattr(outputs, 'logits'):
                # Classification or generation logits
                logits = outputs.logits
                if logits.dim() > 1:
                    # Use mean of logits
                    return logits.mean()
                else:
                    return logits.sum()
            
            elif hasattr(outputs, 'prediction_logits'):
                return outputs.prediction_logits.mean()
            
            elif hasattr(outputs, 'last_hidden_state'):
                return outputs.last_hidden_state.mean()
            
            elif hasattr(outputs, 'pooler_output'):
                return outputs.pooler_output.mean()
            
            elif isinstance(outputs, torch.Tensor):
                return outputs.mean()
            
            elif hasattr(outputs, 'image_embeds'):
                return outputs.image_embeds.mean()
            
            else:
                # Fallback: try to find any tensor in outputs
                for key, value in outputs.items() if hasattr(outputs, 'items') else []:
                    if isinstance(value, torch.Tensor) and value.requires_grad:
                        return value.mean()
                
                logger.error(f"Could not find suitable tensor for target score in outputs: {type(outputs)}")
                return None
                
        except Exception as e:
            logger.error(f"Error calculating target score: {e}")
            return None
