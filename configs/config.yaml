# Cấu hình chung
project:
  name: "MedXplain-VQA"
  description: "Explainable AI for Medical Visual Question Answering"
  seed: 42

# Đường dẫn dữ liệu
data:
  root_dir: "data"
  train_images: "data/images/train"
  val_images: "data/images/val"
  test_images: "data/images/test"
  train_questions: "data/questions/train.jsonl"
  val_questions: "data/questions/val.jsonl"
  test_questions: "data/questions/test.jsonl"
  processed_dir: "data/processed"

# Cấu hình tiền xử lý
preprocessing:
  image:
    size: [384, 384]
    normalize:
      mean: [0.48145466, 0.4578275, 0.40821073]
      std: [0.26862954, 0.26130258, 0.27577711]
  text:
    max_question_length: 128
    max_answer_length: 64

# Cấu hình mô hình
model:
  blip2:
    pretrained_model_name: "Salesforce/blip-vqa-base"
    image_size: 384
    num_query_tokens: 32
    cache_dir: "checkpoints/blip"
    max_answer_length: 64
    freeze_vision_encoder: false
    freeze_qformer: false
    freeze_language_model: false
    vqa_checkpoint_path: null
  
  llm:
    type: "gemini"
    model_name: "models/gemini-1.5-pro"  
    temperature: 0.2
    max_output_tokens: 1024
    top_p: 0.95
    top_k: 40

# Cấu hình huấn luyện
training:
  batch_size: 8
  val_batch_size: 16
  num_epochs: 10
  learning_rate: 0.0001
  weight_decay: 0.01
  warmup_ratio: 0.1
  gradient_accumulation_steps: 2
  max_grad_norm: 1.0
  fp16: true
  num_workers: 4

# Cấu hình đánh giá
evaluation:
  metrics: ["accuracy", "bleu", "cider", "faithfulness"]
  batch_size: 16
  
# Cấu hình logging
logging:
  level: "INFO"
  save_dir: "logs"
  log_interval: 50

# Chain-of-Thought Configuration
explainability:
  reasoning:
    default_flow: 'standard_diagnostic'
    confidence_threshold: 0.5
    max_steps: 8
    enable_differential: true

# MedXplain-VQA Pipeline Configuration  
pipeline:
  default_enable_cot: true
  default_enable_gradcam: true
  save_detailed_results: true
  create_visualizations: true

# Bounding Box Configuration
bounding_box:
  min_area_ratio: 0.001        # Minimum area as ratio of image (0.1%)
  max_area_ratio: 0.25         # Maximum area as ratio of image (25%)
  attention_threshold: 0.3     # Minimum attention score for regions
  min_confidence: 0.1          # Minimum confidence for boxes
  max_boxes: 8                 # Maximum number of boxes per image
  morphology_kernel_size: 3    # Kernel size for morphological operations

# Visual Overlay Configuration  
visual_overlay:
  box_thickness: 3             # Bounding box line thickness
  text_size: 12               # Text annotation size
  alpha: 0.7                  # Transparency for overlays

# Evidence Linking Configuration
evidence_linking:
  spatial_threshold: 0.3       # Spatial relevance threshold
  semantic_threshold: 0.4      # Semantic relevance threshold
  confidence_threshold: 0.2    # Minimum confidence for links
  max_links: 10               # Maximum number of evidence links
